########## Answers for Homework 5 ##########

2.	Average accuracy from 10-folds cross validation is as follow.
		KNN: 0.697197 with SD = 0.049779
		CART: 0.620518 with SD = 0.048222


4.	At first, my assumption is to use four features that are highest standard deviation (feature index: 'glucose-concentration', 'blood-pressure', 'skin-fold-thickness', 'serum-insulin').
	If feature's STD is low, that means that feature has not much different. Then it cannot be used as feature to do classification task.
	
	Anyway, after we try running all possible combinations, the group of four that gives highest average accuracy (10-fold) is ['glucose-concentration', 'blood-pressure', 'skin-fold-thickness', 'age'].
	My assumption is almost correct except 'serum-insulin' => 'age'. After consider the STD, STD of 'serum-insulin' feature is highest and totally much more others.
	My another assumption is because its STD is too high that it contains lots of noise.
	
	Therefore, I choose ['glucose-concentration', 'blood-pressure', 'skin-fold-thickness', 'age'] as the best four features.


5. 	Analyze process and results
		i) 	Data of most features are skewed to the right ('age', 'diabetes-pedigree-function', 'pregnant-time', 'serum-insulin', 'skin-fold-thickness')
			Data of some feature are like normal distribution ('blood-pressure', 'body-mass-index', 'glucose-concentration')
		ii)	KNN performs a little bit better than Decision Tree regarding accuracy, precision, recall and also F1 score.
		
			### KNN results on test data
			Accuracy: 0.681818181818
			Precision: 0.67
			Recall: 0.68
			F1: 0.66

			### CART results on test data
			Accuracy: 0.642857142857
			Precision: 0.65
			Recall: 0.64
			F1: 0.64

			# Note that the results can be different every time we run the code

		iii) When I used only 4 features which performs best average accuracy (10-folds cross validation), KNN outperforms Decision Tree (CART) on all measurements.


		iv)	For KNN, RUN B performs slightly better than RUN A on all measurements including accuracy, precision, recall and F1 when use only four features (the best).
			On the other hand, for decision tree (CART), RUN B performs worse than RUN A on all measurements.

			In my opinion, I think it is general to do feature selection for the better performance model.
			If we use all features, maybe they are comprised of some useless features that can make model go to wrong direction (Noise).
